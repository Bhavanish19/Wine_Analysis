{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsHFwGsvDsHK",
        "outputId": "3823b97e-8215-49d4-c32a-42087d5a4d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!pip install autoviz -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUAlYO-kKBsN",
        "outputId": "a0c5869c-bdf6-4975-afb5-b485220b0055"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iym1FlLYKDsH",
        "outputId": "bd28e0d8-3438-4ebd-fd68-acaaecb76a0f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Qxu12L1FKDvf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "QulDlPwiKDyP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download yasserh/wine-quality-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tfudicQKD1D",
        "outputId": "ed509815-d550-47e0-bf61-cd89a49ffbcb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wine-quality-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip wine-quality-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_ydGDKAKD4g",
        "outputId": "78ee54f3-b53e-4f55-af18-5804523c4a69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  wine-quality-dataset.zip\n",
            "replace WineQT.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Id column\n",
        "df = df.drop(columns=['Id'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "MPoNle9np-GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and y\n",
        "features = df.drop(columns = ['quality'])\n",
        "y = (df['quality'] > 5)*1\n",
        "y.head()"
      ],
      "metadata": {
        "id": "DpMuzRdep-Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Classifier with default Regularization"
      ],
      "metadata": {
        "id": "SYsZxhZed-AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize data\n",
        "X = StandardScaler().fit_transform(features)\n",
        "\n",
        "# Split data into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=99)\n",
        "\n",
        "# Define logistic regression classifier without regularization\n",
        "lr_no_reg = LogisticRegression()\n",
        "\n",
        "# Fit model with data\n",
        "lr_no_reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "VExrM6ssOH9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the coefficients obtained from the model\n",
        "predictors = features.columns\n",
        "coefficients = lr_no_reg.coef_.ravel()                 # ravel() returns a flattened array\n",
        "coef = pd.Series(coefficients, predictors).sort_values()\n",
        "\n",
        "coef.plot(kind='bar', title='Coefficients (no regularization)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7MLDvbInOIAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = lr_no_reg.predict(X_train)\n",
        "y_pred_test = lr_no_reg.predict(X_test)\n",
        "\n",
        "f1_train = f1_score(y_train, y_pred_train)\n",
        "f1_test = f1_score(y_test, y_pred_test)\n",
        "\n",
        "print(f'f1 score for training data (default regularization): {f1_train}')\n",
        "print(f'f1 score for test data (default regularization): {f1_test}')"
      ],
      "metadata": {
        "id": "hPSt9b22OICv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# logistic Regression with L2 Regularization"
      ],
      "metadata": {
        "id": "JDxruoASeIHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write function to collect f1 scores for train and test data while C varies in a logistic regression model\n",
        "C_array = [0.0001, 0.001, 0.01, 0.1, 1]\n",
        "train_array = []\n",
        "test_array = []\n",
        "\n",
        "for x in C_array:\n",
        "    lr = LogisticRegression(C = x, random_state=99)\n",
        "    lr.fit(X_train, y_train)\n",
        "    y_pred_train = lr.predict(X_train)\n",
        "    y_pred_test = lr.predict(X_test)\n",
        "    train_array.append(f1_score(y_train, y_pred_train))\n",
        "    test_array.append(f1_score(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "ttazC7_POIFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot how f1 scores change while changing parameter C in logistic regression model\n",
        "plt.plot(C_array,train_array)\n",
        "plt.plot(C_array,test_array)\n",
        "plt.xlabel('log C')\n",
        "plt.ylabel('f1_score')\n",
        "plt.legend(labels=['train', 'test'])\n",
        "plt.xscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RUCmtU_uOIKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C_array = np.logspace(-4, -2, 100)\n",
        "lr_l2_reg = LogisticRegressionCV(Cs = C_array,\n",
        "                                penalty = 'l2',\n",
        "                                scoring='f1',\n",
        "                                cv=5,\n",
        "                                random_state=99)\n",
        "\n",
        "lr_l2_reg.fit(X_train, y_train)\n",
        "\n",
        "print('Best C: ', lr_l2_reg.C_)\n",
        "print('Best score: ', lr_l2_reg.scores_[1].mean(axis=0).max())"
      ],
      "metadata": {
        "id": "DihRIjh7OIMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_best_ridge = LogisticRegression(C = lr_l2_reg.C_[0])\n",
        "lr_best_ridge.fit(X_train, y_train)\n",
        "\n",
        "y_pred_test = lr_best_ridge.predict(X_test)\n",
        "\n",
        "print(f'f1 score for test data (L2 regularization): {f1_score(y_test, y_pred_test)}')"
      ],
      "metadata": {
        "id": "yJrnJSaKes9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the coefficients obtained from the model\n",
        "coefficients = lr_l2_reg.coef_.ravel()\n",
        "coef = pd.Series(coefficients, predictors).sort_values()\n",
        "\n",
        "coef.plot(kind='bar', title='Coefficients for tuned L2')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qR-kTMCQetAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection using L1 Regularization"
      ],
      "metadata": {
        "id": "ysMMLRYdRSsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C_array = np.logspace(-4, 2, 100)                         # searching between C=0.01 and 100\n",
        "lr_l1_reg = LogisticRegressionCV(Cs = C_array,\n",
        "                                penalty = 'l1',\n",
        "                                solver='liblinear',\n",
        "                                scoring='f1',\n",
        "                                cv=5,\n",
        "                                random_state=99)\n",
        "lr_l1_reg.fit(X, y)\n",
        "\n",
        "print('Best C: ', lr_l1_reg.C_)\n",
        "print('Best score: ', lr_l1_reg.scores_[1].mean(axis=0).max())"
      ],
      "metadata": {
        "id": "nuElZ3N3etF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain score for test data\n",
        "lr_best_lasso = LogisticRegression(C = lr_l1_reg.C_[0])\n",
        "lr_best_lasso.fit(X_train, y_train)\n",
        "\n",
        "y_pred_test = lr_best_lasso.predict(X_test)\n",
        "\n",
        "print(f'f1 score for test data (L1 regularization): {f1_score(y_test, y_pred_test)}')"
      ],
      "metadata": {
        "id": "qPt7JiPNetIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the coefficients obtained from the model\n",
        "coefficients = lr_l1_reg.coef_.ravel()\n",
        "coef = pd.Series(coefficients, predictors).sort_values()\n",
        "\n",
        "coef.plot(kind='bar', title='Coefficients for tuned L1')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mXIzjdXnetLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusions**\n",
        "The best f1 score for Logistic Regression with defaul regularization (L2, C=1): 0.726 \\ The best f1 score for Logistic Regression with L2 regularization (C=0.0034): 0.787 \\ The best f1 score for Logistic Regression with L1 regularization (C=0.142): 0.721"
      ],
      "metadata": {
        "id": "6vY5S2ZgRe02"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zHwEaaB_etO0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}